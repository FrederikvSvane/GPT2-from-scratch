{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1089k  100 1089k    0     0  6842k      0 --:--:-- --:--:-- --:--:-- 6937k\n"
     ]
    }
   ],
   "source": [
    "!curl -o shakespeareDataset.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespeareDataset.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of text: {} characters\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n"
     ]
    }
   ],
   "source": [
    "print(text[:173])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Total characters:  65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(''.join(chars))\n",
    "print(\"Total characters: \", len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up encoding and decoding scheme\n",
    "This is another way of saying, that we find a way to represent the words of the dataset as numbers.\n",
    "\n",
    "To accomplish this, we assign a number to each of the 65 unique characters in the dataset, such that we can represent each letter with a number. \n",
    "\n",
    "For example, 'H' could be represented with the number 1, and 'i' with 2.\n",
    "\n",
    "That way, we could represent the word \"Hi\" with the tensor [1,2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n",
      "[20, 43, 48, 1, 51, 53, 56]\n",
      "Hej mor\n"
     ]
    }
   ],
   "source": [
    "ctoi = { ch:i for i,ch in enumerate(chars) } # char to index\n",
    "itoc = { i:ch for i,ch in enumerate(chars) } # index to char\n",
    "encode = lambda s: [ctoi[ch] for ch in s]\n",
    "decode = lambda a: ''.join([itoc[i] for i in a])\n",
    "\n",
    "print(ctoi)\n",
    "print(itoc)\n",
    "print(encode('Hej mor'))\n",
    "print(decode(encode('Hej mor')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the entire dataset\n",
    "After declaring the encoding and decoding scheme, we apply it to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:173])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the codeblock above, the following was printed:\n",
    "\n",
    "1. The size of the resulting tensor (notice it is as big as the amount of chars in the dataset, as previously printed)\n",
    "\n",
    "2. The first 173 chars in encoded form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning the dataset\n",
    "\n",
    "To avoid overfitting and to reduce the generalization error, we divide the dataset into a training set, and an evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 10\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the context is tensor([18]) the target is 47\n",
      "When the context is tensor([18, 47]) the target is 56\n",
      "When the context is tensor([18, 47, 56]) the target is 57\n",
      "When the context is tensor([18, 47, 56, 57]) the target is 58\n",
      "When the context is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "When the context is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "When the context is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "When the context is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n",
      "When the context is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) the target is 47\n",
      "When the context is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) the target is 64\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for i in range(context_length):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"When the context is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 10])\n",
      "tensor([[57, 61, 43, 39, 56,  0, 26, 43, 60, 43],\n",
      "        [43, 39, 57, 53, 52,  1, 61, 46, 63, 10],\n",
      "        [11,  0, 21,  1, 61, 39, 57,  1, 39, 42],\n",
      "        [20, 13, 30, 16,  1, 21, 21, 21, 10,  0]])\n",
      "targets:\n",
      "torch.Size([4, 10])\n",
      "tensor([[61, 43, 39, 56,  0, 26, 43, 60, 43, 56],\n",
      "        [39, 57, 53, 52,  1, 61, 46, 63, 10,  0],\n",
      "        [ 0, 21,  1, 61, 39, 57,  1, 39, 42, 53],\n",
      "        [13, 30, 16,  1, 21, 21, 21, 10,  0, 31]])\n",
      "When the context is tensor([57]) the target is 61\n",
      "When the context is tensor([57, 61]) the target is 43\n",
      "When the context is tensor([57, 61, 43]) the target is 39\n",
      "When the context is tensor([57, 61, 43, 39]) the target is 56\n",
      "When the context is tensor([57, 61, 43, 39, 56]) the target is 0\n",
      "When the context is tensor([57, 61, 43, 39, 56,  0]) the target is 26\n",
      "When the context is tensor([57, 61, 43, 39, 56,  0, 26]) the target is 43\n",
      "When the context is tensor([57, 61, 43, 39, 56,  0, 26, 43]) the target is 60\n",
      "When the context is tensor([57, 61, 43, 39, 56,  0, 26, 43, 60]) the target is 43\n",
      "When the context is tensor([57, 61, 43, 39, 56,  0, 26, 43, 60, 43]) the target is 56\n",
      "When the context is tensor([43]) the target is 39\n",
      "When the context is tensor([43, 39]) the target is 57\n",
      "When the context is tensor([43, 39, 57]) the target is 53\n",
      "When the context is tensor([43, 39, 57, 53]) the target is 52\n",
      "When the context is tensor([43, 39, 57, 53, 52]) the target is 1\n",
      "When the context is tensor([43, 39, 57, 53, 52,  1]) the target is 61\n",
      "When the context is tensor([43, 39, 57, 53, 52,  1, 61]) the target is 46\n",
      "When the context is tensor([43, 39, 57, 53, 52,  1, 61, 46]) the target is 63\n",
      "When the context is tensor([43, 39, 57, 53, 52,  1, 61, 46, 63]) the target is 10\n",
      "When the context is tensor([43, 39, 57, 53, 52,  1, 61, 46, 63, 10]) the target is 0\n",
      "When the context is tensor([11]) the target is 0\n",
      "When the context is tensor([11,  0]) the target is 21\n",
      "When the context is tensor([11,  0, 21]) the target is 1\n",
      "When the context is tensor([11,  0, 21,  1]) the target is 61\n",
      "When the context is tensor([11,  0, 21,  1, 61]) the target is 39\n",
      "When the context is tensor([11,  0, 21,  1, 61, 39]) the target is 57\n",
      "When the context is tensor([11,  0, 21,  1, 61, 39, 57]) the target is 1\n",
      "When the context is tensor([11,  0, 21,  1, 61, 39, 57,  1]) the target is 39\n",
      "When the context is tensor([11,  0, 21,  1, 61, 39, 57,  1, 39]) the target is 42\n",
      "When the context is tensor([11,  0, 21,  1, 61, 39, 57,  1, 39, 42]) the target is 53\n",
      "When the context is tensor([20]) the target is 13\n",
      "When the context is tensor([20, 13]) the target is 30\n",
      "When the context is tensor([20, 13, 30]) the target is 16\n",
      "When the context is tensor([20, 13, 30, 16]) the target is 1\n",
      "When the context is tensor([20, 13, 30, 16,  1]) the target is 21\n",
      "When the context is tensor([20, 13, 30, 16,  1, 21]) the target is 21\n",
      "When the context is tensor([20, 13, 30, 16,  1, 21, 21]) the target is 21\n",
      "When the context is tensor([20, 13, 30, 16,  1, 21, 21, 21]) the target is 10\n",
      "When the context is tensor([20, 13, 30, 16,  1, 21, 21, 21, 10]) the target is 0\n",
      "When the context is tensor([20, 13, 30, 16,  1, 21, 21, 21, 10,  0]) the target is 31\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "context_length = 10\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+context_length] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(context_length):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When the context is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a general one. It creates garbage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 65]) tensor(4.7985, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7985, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "&.QksPPsxcYgycCA;pbHF\n",
      "L?AtAYG,aybr$AOaKs:!uIENq:VDjQA:\n",
      "SVopLnQ!kmvOAv-aHGDU.,jp;dDtr $UHSmrrTHZ;CKq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            S, V, W = logits.shape \n",
    "            logits = logits.view(S*V, W)\n",
    "            targets = targets.view(S*V)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(len(chars))\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape, loss)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an optimizer and training the model with it using standard backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5165913105010986\n"
     ]
    }
   ],
   "source": [
    "context_length = 32\n",
    "for steps in range(10000):\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ABorer.\n",
      "\n",
      "Whe boun, heporentaw.\n",
      "ARCENEO:\n",
      "\n",
      "MET:\n",
      "\n",
      "y?Tyoryour past, at teicavean, t.\n",
      "\n",
      "ankilico finssl.JNOLeld f INTA:\n",
      "NINTABUKIOHON mers g anwhive d itheame stharceais hemyo nthe ve, iged e w, isakisl wheme'd ly, he ieiclor ssir il m, bG n ybet h, slg di\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=250)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatDev_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
